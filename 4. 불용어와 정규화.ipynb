{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불용어와 정규화\n",
    "\n",
    "1. stopwords 제거\n",
    "\n",
    "2. 문자단위 인코딩\n",
    "\n",
    "3. 어간추출\n",
    "\n",
    "4. 텍스트를 깨끗하게, 그리고 토큰나이징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. stopwords 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sells seashells seashore .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = \"She sells seashells on the seashore.\" # 적용문장\n",
    "custom_stop_word_list = ['she', 'on', 'the', 'am' 'is', 'not'] # custom_stopwords\n",
    "' '.join([word for word in word_tokenize(sentence) if word.lower() not in custom_stop_word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 문자단위 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 66, 46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('A'), ord('B'), ord('.') #숫자로 인코딩 될 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[113, 117, 105, 99, 107, 32, 98, 114, 111, 119, 110, 32, 102, 111, 120]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_vector_ascii(text):\n",
    "    return [ord(a) for a in text]\n",
    "\n",
    "to_vector_ascii('quick brown fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy로 넣기\n",
    "import numpy\n",
    "\n",
    "def to_vector_ascii(text):\n",
    "    return numpy.array([ord(a) for a in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113, 117, 105,  99, 107,  32,  98, 114, 111, 119, 110,  32, 102,\n",
       "       111, 120])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vector_ascii('quick brown fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('T', 1),\n",
       "             ('h', 2),\n",
       "             ('e', 3),\n",
       "             (' ', 4),\n",
       "             ('w', 5),\n",
       "             ('a', 6),\n",
       "             ('t', 7),\n",
       "             ('r', 8),\n",
       "             ('s', 9),\n",
       "             ('i', 10),\n",
       "             ('c', 11),\n",
       "             ('o', 12),\n",
       "             ('u', 13),\n",
       "             ('l', 14),\n",
       "             ('d', 15),\n",
       "             ('b', 16)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def positional_encode_chars(text):\n",
    "    char_to_index = OrderedDict()\n",
    "    index = 1\n",
    "    \n",
    "    for character in text:\n",
    "        if character not in char_to_index:\n",
    "            char_to_index[character] = index\n",
    "            index += 1\n",
    "    \n",
    "    return char_to_index\n",
    "\n",
    "positional_encode_chars(\"The water was as wet as it could be\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 어간추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love play football'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'I love playing football'\n",
    "\n",
    "from nltk.stem import RegexpStemmer\n",
    "regex_stemmer = RegexpStemmer(\"ing$\", min=4) # 사용자가 지정한 정규 표현 기준으로 접사 제거 # ~ing로 끝나는 것들은 어간추출\n",
    "\n",
    "' '.join([regex_stemmer.stem(wd) for wd in sentence.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 텍스트를 깨끗하게... 그리고 토큰나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Without~ #some of the protections afforded'! him by the presidency. Trump will\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Without',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'protections',\n",
       " 'afforded',\n",
       " 'him',\n",
       " 'by',\n",
       " 'the',\n",
       " 'presidency',\n",
       " 'Trump',\n",
       " 'will']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'([^\\s\\w]|_)+', \" \", sentence).split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
